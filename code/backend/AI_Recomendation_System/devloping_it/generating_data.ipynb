{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "6bb0e209-8816-4757-aca5-62c0776fc3df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(   user_id        city  location_x  location_y  age  gender  \\\n",
       " 0        1      Béchar      31.600      -2.250   48    Male   \n",
       " 1        2      Biskra      34.850       5.750   35  Female   \n",
       " 2        3      Béchar      31.610      -2.226   58  Female   \n",
       " 3        4  Tizi Ouzou      36.734       4.047   63  Female   \n",
       " 4        5      Biskra      34.870       5.800   64    Male   \n",
       " \n",
       "                          service_categories_interest reviewed_service_ids  \\\n",
       " 0             [Commercial Cleaning, Quranic Studies]           [438, 231]   \n",
       " 1                         [Masonry, Makeup Services]            [58, 128]   \n",
       " 2  [Post-Construction Cleaning, Quranic Studies, ...                   []   \n",
       " 3  [Local Delivery Services, Commercial Cleaning,...                   []   \n",
       " 4                       [Plumbing, Furniture Moving]                [240]   \n",
       " \n",
       "   click_count_per_service  total_service_views  \n",
       " 0        {438: 1, 231: 1}                    9  \n",
       " 1         {58: 9, 128: 3}                   22  \n",
       " 2                      {}                    3  \n",
       " 3                      {}                    7  \n",
       " 4                {240: 7}                   15  ,\n",
       "    service_id        city  provider_location_x  provider_location_y  \\\n",
       " 0           1        Oran               35.688               -0.605   \n",
       " 1           2     Algiers               36.741                3.089   \n",
       " 2           3  Tizi Ouzou               36.728                4.037   \n",
       " 3           4  Tizi Ouzou               36.745                4.057   \n",
       " 4           5     Algiers               36.786                3.059   \n",
       " \n",
       "           service_category  review_avg  review_count  click_count  \\\n",
       " 0                 Car Wash         3.7            33           88   \n",
       " 1      Commercial Cleaning         3.7            45           28   \n",
       " 2  Painting and Decoration         3.0            19           70   \n",
       " 3                 Car Wash         4.0            33           19   \n",
       " 4          Electrical Work         4.7            28           34   \n",
       " \n",
       "    provider_age  provider_experience  \n",
       " 0            34                    4  \n",
       " 1            56                    4  \n",
       " 2            51                   10  \n",
       " 3            51                   12  \n",
       " 4            43                   17  )"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "# Define constants for service categories and Algerian locations\n",
    "SERVICE_CATEGORIES = [\n",
    "    \"Plumbing\", \"Electrical Work\", \"Painting and Decoration\", \"Masonry\",\n",
    "    \"Residential Cleaning\", \"Commercial Cleaning\", \"Post-Construction Cleaning\",\n",
    "    \"Taxi Services\", \"Furniture Moving\", \"Local Delivery Services\",\n",
    "    \"Car Repair and Maintenance\", \"Tire Services\", \"Car Wash\",\n",
    "    \"Traditional Algerian Catering\", \"Event Catering\",\n",
    "    \"Babysitting\", \"Elderly Companionship Services\",\n",
    "    \"Language Lessons\", \"Quranic Studies\", \"Academic Tutoring\",\n",
    "    \"Hairdressing\", \"Makeup Services\", \"Hammam and Spa Services\"\n",
    "]\n",
    "\n",
    "LOCATIONS = {\n",
    "    \"Algiers\": [\n",
    "        (36.7538, 3.0588), (36.758, 3.063), (36.762, 3.075), (36.730, 3.058),\n",
    "        (36.765, 3.070), (36.745, 3.043), (36.738, 3.071), (36.743, 3.090),\n",
    "        (36.715, 3.127), (36.776, 3.080), (36.786, 3.059), (36.710, 3.075),\n",
    "        (36.745, 3.112), (36.792, 3.085), (36.773, 3.097), (36.783, 3.068),\n",
    "        (36.720, 3.041), (36.734, 3.078), (36.741, 3.089)\n",
    "    ],\n",
    "    \"Oran\": [\n",
    "        (35.698, -0.633), (35.695, -0.608), (35.700, -0.673), (35.720, -0.630), (35.688, -0.605)\n",
    "    ],\n",
    "    \"Tizi Ouzou\": [\n",
    "        (36.734, 4.047), (36.745, 4.057), (36.728, 4.037), (36.746, 4.072)\n",
    "    ],\n",
    "    \"Biskra\": [\n",
    "        (34.866, 5.733), (34.850, 5.750), (34.880, 5.730), (34.870, 5.800)\n",
    "    ],\n",
    "    \"Béchar\": [\n",
    "        (31.610, -2.226), (31.635, -2.217), (31.600, -2.250), (31.615, -2.270)\n",
    "    ],\n",
    "    \"Bejaia\": [\n",
    "        (36.759, 5.084), (36.750, 5.100), (36.780, 5.070), (36.760, 5.110)\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Helper function to generate location with city and avoid duplicates\n",
    "def generate_location(assigned_locations):\n",
    "    city = random.choice(list(LOCATIONS.keys()))\n",
    "    available_locations = [loc for loc in LOCATIONS[city] if loc not in assigned_locations]\n",
    "    if not available_locations:\n",
    "        return None, None  # No available locations left\n",
    "    location = random.choice(available_locations)\n",
    "    assigned_locations.add(location)\n",
    "    return city, location\n",
    "\n",
    "# Generate user data with city assignment, avoiding duplicate locations\n",
    "def generate_user_data(user_id, assigned_locations):\n",
    "    city, location = generate_location(assigned_locations)\n",
    "    if city is None:\n",
    "        return None  # No available location left\n",
    "    categories_of_interest = random.sample(SERVICE_CATEGORIES, random.randint(2, 4))\n",
    "    reviewed_service_ids = random.sample(range(1, 501), random.randint(0, 3))\n",
    "    click_count_per_service = {sid: random.randint(1, 10) for sid in reviewed_service_ids}\n",
    "    total_service_views = sum(click_count_per_service.values()) + random.randint(0, 10)\n",
    "    \n",
    "    return {\n",
    "        \"user_id\": user_id,\n",
    "        \"city\": city,\n",
    "        \"location_x\": location[0],\n",
    "        \"location_y\": location[1],\n",
    "        \"age\": random.randint(18, 65),\n",
    "        \"gender\": random.choice([\"Male\", \"Female\"]),\n",
    "        \"service_categories_interest\": categories_of_interest,\n",
    "        \"reviewed_service_ids\": reviewed_service_ids,\n",
    "        \"click_count_per_service\": click_count_per_service,\n",
    "        \"total_service_views\": total_service_views\n",
    "    }\n",
    "\n",
    "# Generate service data with city assignment, avoiding duplicate locations\n",
    "def generate_service_data(service_id, assigned_locations):\n",
    "    city, location = generate_location(assigned_locations)\n",
    "    if city is None:\n",
    "        return None  # No available location left\n",
    "    category = random.choice(SERVICE_CATEGORIES)\n",
    "    click_count = random.randint(0, 100)\n",
    "    \n",
    "    return {\n",
    "        \"service_id\": service_id,\n",
    "        \"city\": city,\n",
    "        \"provider_location_x\": location[0],\n",
    "        \"provider_location_y\": location[1],\n",
    "        \"service_category\": category,\n",
    "        \"review_avg\": round(random.uniform(3.0, 5.0), 1),\n",
    "        \"review_count\": random.randint(1, 50),\n",
    "        \"click_count\": click_count,\n",
    "        \"provider_age\": random.randint(25, 60),\n",
    "        \"provider_experience\": random.randint(1, 20)\n",
    "    }\n",
    "\n",
    "# Initialize set to track assigned locations\n",
    "assigned_locations = set()\n",
    "\n",
    "# Generate datasets\n",
    "user_data = []\n",
    "for user_id in range(1, 2001):\n",
    "    user = generate_user_data(user_id, assigned_locations)\n",
    "    if user:\n",
    "        user_data.append(user)\n",
    "\n",
    "service_data = []\n",
    "assigned_locations.clear()  # Reset for services to avoid overlap with users' locations\n",
    "for service_id in range(1, 501):\n",
    "    service = generate_service_data(service_id, assigned_locations)\n",
    "    if service:\n",
    "        service_data.append(service)\n",
    "\n",
    "# Convert to DataFrames\n",
    "user_df = pd.DataFrame(user_data)\n",
    "service_df = pd.DataFrame(service_data)\n",
    "\n",
    "# Display the first few rows of each dataset\n",
    "user_df.head(), service_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "710f785e-75c4-4bea-af4b-f5879e56493b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "city\n",
      "Algiers       324\n",
      "Bejaia        336\n",
      "Biskra        338\n",
      "Béchar        317\n",
      "Oran          351\n",
      "Tizi Ouzou    334\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(clustered_user_df.groupby(['city']).size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "8e3e7323-c68e-4a19-bc9b-493c980ac99c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>city</th>\n",
       "      <th>location_x</th>\n",
       "      <th>location_y</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>service_categories_interest</th>\n",
       "      <th>reviewed_service_ids</th>\n",
       "      <th>click_count_per_service</th>\n",
       "      <th>total_service_views</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Biskra</td>\n",
       "      <td>34.85</td>\n",
       "      <td>5.75</td>\n",
       "      <td>61</td>\n",
       "      <td>Female</td>\n",
       "      <td>[Painting and Decoration, Residential Cleaning...</td>\n",
       "      <td>[427, 346, 87]</td>\n",
       "      <td>{427: 3, 346: 6, 87: 2}</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>Biskra</td>\n",
       "      <td>34.85</td>\n",
       "      <td>5.75</td>\n",
       "      <td>49</td>\n",
       "      <td>Female</td>\n",
       "      <td>[Plumbing, Makeup Services, Hammam and Spa Ser...</td>\n",
       "      <td>[432, 364]</td>\n",
       "      <td>{432: 10, 364: 5}</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12</td>\n",
       "      <td>Biskra</td>\n",
       "      <td>34.85</td>\n",
       "      <td>5.75</td>\n",
       "      <td>42</td>\n",
       "      <td>Female</td>\n",
       "      <td>[Hairdressing, Commercial Cleaning]</td>\n",
       "      <td>[50]</td>\n",
       "      <td>{50: 2}</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id    city  location_x  location_y  age  gender  \\\n",
       "0        1  Biskra       34.85        5.75   61  Female   \n",
       "1        4  Biskra       34.85        5.75   49  Female   \n",
       "3       12  Biskra       34.85        5.75   42  Female   \n",
       "\n",
       "                         service_categories_interest reviewed_service_ids  \\\n",
       "0  [Painting and Decoration, Residential Cleaning...       [427, 346, 87]   \n",
       "1  [Plumbing, Makeup Services, Hammam and Spa Ser...           [432, 364]   \n",
       "3                [Hairdressing, Commercial Cleaning]                 [50]   \n",
       "\n",
       "   click_count_per_service  total_service_views  cluster  \n",
       "0  {427: 3, 346: 6, 87: 2}                   16        0  \n",
       "1        {432: 10, 364: 5}                   21        0  \n",
       "3                  {50: 2}                    6        0  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " clustered_user_df[clustered_user_df['cluster'] == 0].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "baad97af-87dd-460b-8751-783846cb272e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>city</th>\n",
       "      <th>location_x</th>\n",
       "      <th>location_y</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>service_categories_interest</th>\n",
       "      <th>reviewed_service_ids</th>\n",
       "      <th>click_count_per_service</th>\n",
       "      <th>total_service_views</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22</td>\n",
       "      <td>Biskra</td>\n",
       "      <td>34.866</td>\n",
       "      <td>5.733</td>\n",
       "      <td>39</td>\n",
       "      <td>Male</td>\n",
       "      <td>[Electrical Work, Car Wash, Traditional Algeri...</td>\n",
       "      <td>[124, 226, 21]</td>\n",
       "      <td>{124: 7, 226: 5, 21: 3}</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>34</td>\n",
       "      <td>Biskra</td>\n",
       "      <td>34.866</td>\n",
       "      <td>5.733</td>\n",
       "      <td>53</td>\n",
       "      <td>Male</td>\n",
       "      <td>[Elderly Companionship Services, Language Less...</td>\n",
       "      <td>[]</td>\n",
       "      <td>{}</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>38</td>\n",
       "      <td>Biskra</td>\n",
       "      <td>34.866</td>\n",
       "      <td>5.733</td>\n",
       "      <td>46</td>\n",
       "      <td>Male</td>\n",
       "      <td>[Tire Services, Hammam and Spa Services, Babys...</td>\n",
       "      <td>[86]</td>\n",
       "      <td>{86: 9}</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id    city  location_x  location_y  age gender  \\\n",
       "4       22  Biskra      34.866       5.733   39   Male   \n",
       "8       34  Biskra      34.866       5.733   53   Male   \n",
       "9       38  Biskra      34.866       5.733   46   Male   \n",
       "\n",
       "                         service_categories_interest reviewed_service_ids  \\\n",
       "4  [Electrical Work, Car Wash, Traditional Algeri...       [124, 226, 21]   \n",
       "8  [Elderly Companionship Services, Language Less...                   []   \n",
       "9  [Tire Services, Hammam and Spa Services, Babys...                 [86]   \n",
       "\n",
       "   click_count_per_service  total_service_views  cluster  \n",
       "4  {124: 7, 226: 5, 21: 3}                   25        1  \n",
       "8                       {}                    3        1  \n",
       "9                  {86: 9}                   11        1  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " clustered_user_df[clustered_user_df['cluster'] == 1].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e966ad8f-f632-40fd-8b0c-bf6c81fffd49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustering for city: Biskra\n",
      "Clustering for city: Algiers\n",
      "Clustering for city: Béchar\n",
      "Clustering for city: Oran\n",
      "Clustering for city: Bejaia\n",
      "Clustering for city: Tizi Ouzou\n",
      "   user_id    city  cluster  location_x  location_y\n",
      "0        1  Biskra        0      34.850       5.750\n",
      "1        4  Biskra        0      34.850       5.750\n",
      "2        7  Biskra        3      34.866       5.733\n",
      "3       12  Biskra        0      34.850       5.750\n",
      "4       22  Biskra        1      34.866       5.733\n",
      "Unique clusters: [ 0  3  1  2  4  7  5  9  6  8 11 10 13 12 14 17 18 16 15 19 21 20 23 22\n",
      " 24 27 25 29 28 26]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "# Define function to extract features for clustering\n",
    "def generate_city_features(city_users):\n",
    "    # Combine features for clustering\n",
    "    features = pd.concat([\n",
    "        city_users[['location_x', 'location_y']],  # Geographic location\n",
    "        city_users[['age']],  # Age\n",
    "        pd.get_dummies(city_users['gender'], prefix=\"gender\"),  # Gender (one-hot)\n",
    "    ], axis=1)\n",
    "    \n",
    "    # Normalize features\n",
    "    scaler = StandardScaler()\n",
    "    return scaler.fit_transform(features)\n",
    "\n",
    "# Train K-Means clustering for each city with unique cluster IDs\n",
    "def train_city_clusters_with_offset(user_df, n_clusters_per_city=5):\n",
    "    city_clusters = {}\n",
    "    cluster_offset = 0  # Tracks cumulative offset for unique cluster IDs\n",
    "    \n",
    "    for city in user_df['city'].unique():\n",
    "        print(f\"Clustering for city: {city}\")\n",
    "        \n",
    "        # Filter users by city\n",
    "        city_users = user_df[user_df['city'] == city].reset_index(drop=True)\n",
    "        \n",
    "        # Generate features for clustering\n",
    "        city_features = generate_city_features(city_users)\n",
    "        \n",
    "        # Apply K-Means\n",
    "        kmeans = KMeans(n_clusters=n_clusters_per_city, random_state=42)\n",
    "        city_users['cluster'] = kmeans.fit_predict(city_features) + cluster_offset\n",
    "        \n",
    "        # Update cluster offset\n",
    "        cluster_offset += n_clusters_per_city\n",
    "        \n",
    "        # Store clustered data\n",
    "        city_clusters[city] = city_users\n",
    "    \n",
    "    return city_clusters\n",
    "\n",
    "# Train clustering for each city with unique cluster IDs\n",
    "n_clusters_per_city = 5  # Adjust based on city size\n",
    "city_cluster_results = train_city_clusters_with_offset(user_df, n_clusters_per_city=n_clusters_per_city)\n",
    "\n",
    "# Combine results into a single DataFrame\n",
    "clustered_user_df = pd.concat(city_cluster_results.values(), ignore_index=True)\n",
    "\n",
    "# Display the first few rows of the clustered data\n",
    "print(clustered_user_df[['user_id', 'city', 'cluster', 'location_x', 'location_y']].head())\n",
    "\n",
    "# Check the unique clusters\n",
    "print(\"Unique clusters:\", clustered_user_df['cluster'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "bb168213-7a85-4c82-815b-84236d9f6a64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustering for city: Biskra\n",
      "Clustering for city: Algiers\n",
      "Clustering for city: Béchar\n",
      "Clustering for city: Oran\n",
      "Clustering for city: Bejaia\n",
      "Clustering for city: Tizi Ouzou\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[75], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel saved to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Example usage after training the model:\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m kmeans, scaler \u001b[38;5;241m=\u001b[39m train_city_clusters_with_offset(user_df, n_clusters_per_city\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[0;32m     10\u001b[0m save_model(kmeans, scaler)\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the trained KMeans model and scaler\n",
    "def save_model(kmeans, scaler, filename=\"clustering_model.pkl\"):\n",
    "    joblib.dump((kmeans, scaler), filename)\n",
    "    print(f\"Model saved to {filename}\")\n",
    "\n",
    "# Example usage after training the model:\n",
    "kmeans, scaler = train_city_clusters_with_offset(user_df, n_clusters_per_city=5)\n",
    "save_model(kmeans, scaler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a927d9e2-07d1-4bcc-a79f-f131d51ca495",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustering for city: Biskra\n",
      "Clustering for city: Algiers\n",
      "Clustering for city: Béchar\n",
      "Clustering for city: Oran\n",
      "Clustering for city: Bejaia\n",
      "Clustering for city: Tizi Ouzou\n",
      "   user_id    city  cluster  location_x  location_y\n",
      "0        1  Biskra        0      34.850       5.750\n",
      "1        4  Biskra        0      34.850       5.750\n",
      "2        7  Biskra        3      34.866       5.733\n",
      "3       12  Biskra        0      34.850       5.750\n",
      "4       22  Biskra        1      34.866       5.733\n",
      "Model and scalers saved to clustering_model.pkl\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "# Define function to extract features for clustering\n",
    "def generate_city_features(city_users):\n",
    "    # Combine features for clustering\n",
    "    features = pd.concat([\n",
    "        city_users[['location_x', 'location_y']],  # Geographic location\n",
    "        city_users[['age']],  # Age\n",
    "        pd.get_dummies(city_users['gender'], prefix=\"gender\"),  # Gender (one-hot)\n",
    "    ], axis=1)\n",
    "    \n",
    "    # Normalize features\n",
    "    scaler = StandardScaler()\n",
    "    return scaler.fit_transform(features), scaler\n",
    "\n",
    "# Train K-Means clustering for each city with unique cluster IDs\n",
    "def train_city_clusters_with_offset(user_df, n_clusters_per_city=5):\n",
    "    city_clusters = {}\n",
    "    cluster_offset = 0  # Tracks cumulative offset for unique cluster IDs\n",
    "    all_city_scalers = {}\n",
    "    \n",
    "    for city in user_df['city'].unique():\n",
    "        print(f\"Clustering for city: {city}\")\n",
    "        \n",
    "        # Filter users by city\n",
    "        city_users = user_df[user_df['city'] == city].reset_index(drop=True)\n",
    "        \n",
    "        # Generate features for clustering and scaler\n",
    "        city_features, scaler = generate_city_features(city_users)\n",
    "        \n",
    "        # Apply K-Means\n",
    "        kmeans = KMeans(n_clusters=n_clusters_per_city, random_state=42)\n",
    "        city_users['cluster'] = kmeans.fit_predict(city_features) + cluster_offset\n",
    "        \n",
    "        # Update cluster offset\n",
    "        cluster_offset += n_clusters_per_city\n",
    "        \n",
    "        # Store clustered data and the scaler\n",
    "        city_clusters[city] = city_users\n",
    "        all_city_scalers[city] = scaler\n",
    "    \n",
    "    return city_clusters, all_city_scalers\n",
    "\n",
    "# Train clustering for each city with unique cluster IDs\n",
    "n_clusters_per_city = 5  # Adjust based on city size\n",
    "city_cluster_results, all_city_scalers = train_city_clusters_with_offset(user_df, n_clusters_per_city=n_clusters_per_city)\n",
    "\n",
    "# Combine results into a single DataFrame\n",
    "clustered_user_df = pd.concat(city_cluster_results.values(), ignore_index=True)\n",
    "\n",
    "# Display the first few rows of the clustered data\n",
    "print(clustered_user_df[['user_id', 'city', 'cluster', 'location_x', 'location_y']].head())\n",
    "\n",
    "# Save model and scalers\n",
    "def save_model(kmeans_dict, scalers_dict, filename=\"clustering_model.pkl\"):\n",
    "    # Save models and scalers\n",
    "    joblib.dump((kmeans_dict, scalers_dict), filename)\n",
    "    print(f\"Model and scalers saved to {filename}\")\n",
    "\n",
    "# Save the model and scalers\n",
    "save_model(city_cluster_results, all_city_scalers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9699b1e7-8184-42d0-befb-f7d7d5cee9a6",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and scalers loaded from clustering_model.pkl\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The feature names should match those that were passed during fit.\nFeature names seen at fit time, yet now missing:\n- gender_Female\n- gender_Male\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[77], line 21\u001b[0m\n\u001b[0;32m     13\u001b[0m new_user_data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocation_x\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m36.7538\u001b[39m],  \u001b[38;5;66;03m# Example location\u001b[39;00m\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocation_y\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m3.0588\u001b[39m],   \u001b[38;5;66;03m# Example location\u001b[39;00m\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mage\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m30\u001b[39m],               \u001b[38;5;66;03m# Example age\u001b[39;00m\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgender\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMale\u001b[39m\u001b[38;5;124m'\u001b[39m]         \u001b[38;5;66;03m# Example gender\u001b[39;00m\n\u001b[0;32m     18\u001b[0m })\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Preprocess new user data\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m new_user_features, scaler \u001b[38;5;241m=\u001b[39m \u001b[43mscalers_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mAlgiers\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_user_data\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlocation_x\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlocation_y\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mage\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Transform using the scaler for Algiers\u001b[39;00m\n\u001b[0;32m     22\u001b[0m new_user_cluster \u001b[38;5;241m=\u001b[39m kmeans_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAlgiers\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mpredict(new_user_features)  \u001b[38;5;66;03m# Predict the cluster\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPredicted cluster for new user:\u001b[39m\u001b[38;5;124m\"\u001b[39m, new_user_cluster)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\utils\\_set_output.py:316\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    314\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    315\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 316\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    317\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    318\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    319\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    320\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    321\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    322\u001b[0m         )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\preprocessing\\_data.py:1045\u001b[0m, in \u001b[0;36mStandardScaler.transform\u001b[1;34m(self, X, copy)\u001b[0m\n\u001b[0;32m   1042\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m   1044\u001b[0m copy \u001b[38;5;241m=\u001b[39m copy \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy\n\u001b[1;32m-> 1045\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1046\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1047\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1048\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1049\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1050\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFLOAT_DTYPES\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1051\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_writeable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1052\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1053\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1055\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sparse\u001b[38;5;241m.\u001b[39missparse(X):\n\u001b[0;32m   1056\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwith_mean:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py:608\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    537\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_validate_data\u001b[39m(\n\u001b[0;32m    538\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    539\u001b[0m     X\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mno_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    544\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params,\n\u001b[0;32m    545\u001b[0m ):\n\u001b[0;32m    546\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Validate input data and set or check the `n_features_in_` attribute.\u001b[39;00m\n\u001b[0;32m    547\u001b[0m \n\u001b[0;32m    548\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    606\u001b[0m \u001b[38;5;124;03m        validated.\u001b[39;00m\n\u001b[0;32m    607\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 608\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_feature_names\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    610\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_tags()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires_y\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m    611\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    612\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m estimator \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    613\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires y to be passed, but the target y is None.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    614\u001b[0m         )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py:535\u001b[0m, in \u001b[0;36mBaseEstimator._check_feature_names\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    530\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m missing_names \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m unexpected_names:\n\u001b[0;32m    531\u001b[0m     message \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    532\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature names must be in the same order as they were in fit.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    533\u001b[0m     )\n\u001b[1;32m--> 535\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(message)\n",
      "\u001b[1;31mValueError\u001b[0m: The feature names should match those that were passed during fit.\nFeature names seen at fit time, yet now missing:\n- gender_Female\n- gender_Male\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Load the trained KMeans models and scalers\n",
    "def load_model(filename=\"clustering_model.pkl\"):\n",
    "    kmeans_dict, scalers_dict = joblib.load(filename)\n",
    "    print(f\"Model and scalers loaded from {filename}\")\n",
    "    return kmeans_dict, scalers_dict\n",
    "\n",
    "# Load the model and scalers\n",
    "kmeans_dict, scalers_dict = load_model()\n",
    "\n",
    "# Example: Predicting cluster for new user in Algiers\n",
    "new_user_data = pd.DataFrame({\n",
    "    'location_x': [36.7538],  # Example location\n",
    "    'location_y': [3.0588],   # Example location\n",
    "    'age': [30],               # Example age\n",
    "    'gender': ['Male']         # Example gender\n",
    "})\n",
    "\n",
    "# Preprocess new user data\n",
    "new_user_features, scaler = scalers_dict['Algiers'].transform(new_user_data[['location_x', 'location_y', 'age']])  # Transform using the scaler for Algiers\n",
    "new_user_cluster = kmeans_dict['Algiers'].predict(new_user_features)  # Predict the cluster\n",
    "\n",
    "print(\"Predicted cluster for new user:\", new_user_cluster)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b13c456a-c6a9-49ac-97cd-a39a4d5ed862",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustering for city: Béchar\n",
      "Clustering for city: Algiers\n",
      "Clustering for city: Biskra\n",
      "Clustering for city: Oran\n",
      "Clustering for city: Tizi Ouzou\n",
      "Clustering for city: Bejaia\n",
      "Model and scalers saved to clustering_model.pkl\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import pandas as pd\n",
    "\n",
    "# Helper function to perform one-hot encoding consistently for service categories interest\n",
    "def encode_service_categories(city_users):\n",
    "    # Apply MultiLabelBinarizer to transform the service categories into binary columns\n",
    "    mlb = MultiLabelBinarizer(classes=SERVICE_CATEGORIES)  # Ensure it uses the full list of categories\n",
    "    return mlb.fit_transform(city_users['service_categories_interest'])\n",
    "\n",
    "# Feature extraction for city data with one-hot encoding for gender and service categories interest\n",
    "def generate_city_features(city_users):\n",
    "    # One-hot encode gender\n",
    "    gender_encoded = encode_gender(city_users['gender'])\n",
    "    \n",
    "    # One-hot encode service categories interest\n",
    "    service_interest_encoded = encode_service_categories(city_users)\n",
    "    \n",
    "    # Combine features for clustering\n",
    "    features = pd.concat([\n",
    "        city_users[['location_x', 'location_y']],  # Geographic location\n",
    "        city_users[['age']],  # Age\n",
    "        pd.DataFrame(gender_encoded, columns=[\"gender_Male\"]),  # One-hot encoded gender\n",
    "        pd.DataFrame(service_interest_encoded, columns=SERVICE_CATEGORIES),  # One-hot encoded service categories\n",
    "    ], axis=1)\n",
    "    \n",
    "    # Normalize features\n",
    "    scaler = StandardScaler()\n",
    "    return scaler.fit_transform(features), scaler\n",
    "\n",
    "# Train K-Means clustering for each city with unique cluster IDs\n",
    "def train_city_clusters_with_offset(user_df, n_clusters_per_city=5):\n",
    "    city_clusters = {}\n",
    "    cluster_offset = 0  # Tracks cumulative offset for unique cluster IDs\n",
    "    all_city_scalers = {}\n",
    "    all_city_encoders = {}\n",
    "    \n",
    "    for city in user_df['city'].unique():\n",
    "        print(f\"Clustering for city: {city}\")\n",
    "        \n",
    "        # Filter users by city\n",
    "        city_users = user_df[user_df['city'] == city].reset_index(drop=True)\n",
    "        \n",
    "        # Generate features for clustering and scaler\n",
    "        city_features, scaler = generate_city_features(city_users)\n",
    "        \n",
    "        # Apply K-Means\n",
    "        kmeans = KMeans(n_clusters=n_clusters_per_city, random_state=42)\n",
    "        city_users['cluster'] = kmeans.fit_predict(city_features) + cluster_offset\n",
    "        \n",
    "        # Update cluster offset\n",
    "        cluster_offset += n_clusters_per_city\n",
    "        \n",
    "        # Store clustered data, scaler, and encoder\n",
    "        city_clusters[city] = city_users\n",
    "        all_city_scalers[city] = scaler\n",
    "        all_city_encoders[city] = MultiLabelBinarizer(classes=SERVICE_CATEGORIES).fit(city_users['service_categories_interest'])\n",
    "    \n",
    "    return city_clusters, all_city_scalers, all_city_encoders\n",
    "\n",
    "# Train clustering for each city with unique cluster IDs\n",
    "n_clusters_per_city = 5  # Adjust based on city size\n",
    "city_cluster_results, all_city_scalers, all_city_encoders = train_city_clusters_with_offset(user_df, n_clusters_per_city=n_clusters_per_city)\n",
    "\n",
    "# Save the model, scalers, and encoders\n",
    "def save_model(kmeans_dict, scalers_dict, encoders_dict, filename=\"clustering_model.pkl\"):\n",
    "    joblib.dump((kmeans_dict, scalers_dict, encoders_dict), filename)\n",
    "    print(f\"Model and scalers saved to {filename}\")\n",
    "\n",
    "# Save the model and scalers\n",
    "save_model(city_cluster_results, all_city_scalers, all_city_encoders)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "a7653731-3ef4-4a96-bca4-a0ee1d76e10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure clusters are assigned to the user_df dataframe\n",
    "def assign_clusters_to_user_df(city_cluster_results):\n",
    "    # Iterate through the city clusters and assign the cluster labels to user_df\n",
    "    user_df_list = []\n",
    "    for city, city_users in city_cluster_results.items():\n",
    "        user_df_list.append(city_users[['user_id', 'city', 'location_x', 'location_y', 'age', 'gender', 'service_categories_interest', 'cluster']])\n",
    "    \n",
    "    # Concatenate all city clusters back into a single dataframe\n",
    "    final_user_df = pd.concat(user_df_list, ignore_index=True)\n",
    "    return final_user_df\n",
    "\n",
    "# Ensure user_df has the correct cluster assignments\n",
    "user_df = assign_clusters_to_user_df(city_cluster_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "adc94ec1-2ae6-4bf2-adcd-fa5791c5692c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustering for city: Béchar\n",
      "Clustering for city: Biskra\n",
      "Clustering for city: Tizi Ouzou\n",
      "Clustering for city: Bejaia\n",
      "Clustering for city: Algiers\n",
      "Clustering for city: Oran\n",
      "Model and scalers saved to clustering_model.pkl\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.cluster import KMeans\n",
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "# Define constants for service categories\n",
    "SERVICE_CATEGORIES = [\n",
    "    \"Plumbing\", \"Electrical Work\", \"Painting and Decoration\", \"Masonry\",\n",
    "    \"Residential Cleaning\", \"Commercial Cleaning\", \"Post-Construction Cleaning\",\n",
    "    \"Taxi Services\", \"Furniture Moving\", \"Local Delivery Services\",\n",
    "    \"Car Repair and Maintenance\", \"Tire Services\", \"Car Wash\",\n",
    "    \"Traditional Algerian Catering\", \"Event Catering\",\n",
    "    \"Babysitting\", \"Elderly Companionship Services\",\n",
    "    \"Language Lessons\", \"Quranic Studies\", \"Academic Tutoring\",\n",
    "    \"Hairdressing\", \"Makeup Services\", \"Hammam and Spa Services\"\n",
    "]\n",
    "\n",
    "# Helper function to one-hot encode service categories interest\n",
    "def encode_service_categories(city_users):\n",
    "    # Use MultiLabelBinarizer for multi-hot encoding service interests\n",
    "    mlb = MultiLabelBinarizer(classes=SERVICE_CATEGORIES)\n",
    "    return mlb.fit_transform(city_users['service_categories_interest'])\n",
    "\n",
    "# Feature extraction for city data with one-hot encoding for gender and service categories interest\n",
    "def generate_city_features(city_users):\n",
    "    # One-hot encode gender\n",
    "    gender_encoded = encode_gender(city_users['gender'])\n",
    "    \n",
    "    # One-hot encode service categories interest\n",
    "    service_interest_encoded = encode_service_categories(city_users)\n",
    "    \n",
    "    # Combine features for clustering\n",
    "    features = pd.concat([\n",
    "        city_users[['location_x', 'location_y']],  # Geographic location\n",
    "        city_users[['age']],  # Age\n",
    "        pd.DataFrame(gender_encoded, columns=[\"gender_Male\"]),  # One-hot encoded gender\n",
    "        pd.DataFrame(service_interest_encoded, columns=SERVICE_CATEGORIES),  # One-hot encoded service categories\n",
    "    ], axis=1)\n",
    "    \n",
    "    # Normalize features\n",
    "    scaler = StandardScaler()\n",
    "    return scaler.fit_transform(features), scaler\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "\n",
    "# Train K-Means clustering for each city with unique cluster IDs, adjusting for small sample sizes\n",
    "def train_city_clusters_with_offset(user_df, n_clusters_per_city=5):\n",
    "    city_clusters = {}\n",
    "    cluster_offset = 0  # Tracks cumulative offset for unique cluster IDs\n",
    "    all_city_scalers = {}\n",
    "    all_city_encoders = {}\n",
    "    \n",
    "    for city in user_df['city'].unique():\n",
    "        print(f\"Clustering for city: {city}\")\n",
    "        \n",
    "        # Filter users by city\n",
    "        city_users = user_df[user_df['city'] == city].reset_index(drop=True)\n",
    "        \n",
    "        # Check if the number of users is smaller than n_clusters_per_city\n",
    "        num_users = len(city_users)\n",
    "        clusters_to_use = min(num_users, n_clusters_per_city)  # Use the smaller of num_users or n_clusters_per_city\n",
    "        \n",
    "        # Generate features for clustering and scaler\n",
    "        city_features, scaler = generate_city_features(city_users)\n",
    "        \n",
    "        # Apply K-Means with the adjusted number of clusters\n",
    "        kmeans = KMeans(n_clusters=clusters_to_use, random_state=42)\n",
    "        city_users['cluster'] = kmeans.fit_predict(city_features) + cluster_offset\n",
    "        \n",
    "        # Update cluster offset\n",
    "        cluster_offset += clusters_to_use\n",
    "        \n",
    "        # Store clustered data, scaler, and encoder\n",
    "        city_clusters[city] = city_users\n",
    "        all_city_scalers[city] = scaler\n",
    "        all_city_encoders[city] = MultiLabelBinarizer(classes=SERVICE_CATEGORIES).fit(city_users['service_categories_interest'])\n",
    "    \n",
    "    return city_clusters, all_city_scalers, all_city_encoders\n",
    "\n",
    "# Train clustering for each city with unique cluster IDs\n",
    "n_clusters_per_city = 5  # Adjust based on city size\n",
    "city_cluster_results, all_city_scalers, all_city_encoders = train_city_clusters_with_offset(user_df, n_clusters_per_city=n_clusters_per_city)\n",
    "\n",
    "# Save the model, scalers, and encoders\n",
    "def save_model(kmeans_dict, scalers_dict, encoders_dict, filename=\"clustering_model.pkl\"):\n",
    "    joblib.dump((kmeans_dict, scalers_dict, encoders_dict), filename)\n",
    "    print(f\"Model and scalers saved to {filename}\")\n",
    "\n",
    "# Save the model and scalers\n",
    "save_model(city_cluster_results, all_city_scalers, all_city_encoders)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "db1bfbe2-5fa7-4818-8fa5-153a5fb169a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>city</th>\n",
       "      <th>location_x</th>\n",
       "      <th>location_y</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>service_categories_interest</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>26</td>\n",
       "      <td>Algiers</td>\n",
       "      <td>36.7830</td>\n",
       "      <td>3.0680</td>\n",
       "      <td>46</td>\n",
       "      <td>Female</td>\n",
       "      <td>[Furniture Moving, Traditional Algerian Cateri...</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>56</td>\n",
       "      <td>Algiers</td>\n",
       "      <td>36.7340</td>\n",
       "      <td>3.0780</td>\n",
       "      <td>50</td>\n",
       "      <td>Female</td>\n",
       "      <td>[Quranic Studies, Local Delivery Services, Tir...</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>64</td>\n",
       "      <td>Algiers</td>\n",
       "      <td>36.7920</td>\n",
       "      <td>3.0850</td>\n",
       "      <td>45</td>\n",
       "      <td>Female</td>\n",
       "      <td>[Painting and Decoration, Local Delivery Servi...</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>68</td>\n",
       "      <td>Algiers</td>\n",
       "      <td>36.7650</td>\n",
       "      <td>3.0700</td>\n",
       "      <td>22</td>\n",
       "      <td>Female</td>\n",
       "      <td>[Event Catering, Car Repair and Maintenance]</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>104</td>\n",
       "      <td>Algiers</td>\n",
       "      <td>36.7538</td>\n",
       "      <td>3.0588</td>\n",
       "      <td>45</td>\n",
       "      <td>Female</td>\n",
       "      <td>[Traditional Algerian Catering, Taxi Services]</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>136</td>\n",
       "      <td>Algiers</td>\n",
       "      <td>36.7860</td>\n",
       "      <td>3.0590</td>\n",
       "      <td>23</td>\n",
       "      <td>Female</td>\n",
       "      <td>[Traditional Algerian Catering, Local Delivery...</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    user_id     city  location_x  location_y  age  gender  \\\n",
       "21       26  Algiers     36.7830      3.0680   46  Female   \n",
       "24       56  Algiers     36.7340      3.0780   50  Female   \n",
       "27       64  Algiers     36.7920      3.0850   45  Female   \n",
       "28       68  Algiers     36.7650      3.0700   22  Female   \n",
       "32      104  Algiers     36.7538      3.0588   45  Female   \n",
       "34      136  Algiers     36.7860      3.0590   23  Female   \n",
       "\n",
       "                          service_categories_interest  cluster  \n",
       "21  [Furniture Moving, Traditional Algerian Cateri...       17  \n",
       "24  [Quranic Studies, Local Delivery Services, Tir...       17  \n",
       "27  [Painting and Decoration, Local Delivery Servi...       17  \n",
       "28       [Event Catering, Car Repair and Maintenance]       17  \n",
       "32     [Traditional Algerian Catering, Taxi Services]       17  \n",
       "34  [Traditional Algerian Catering, Local Delivery...       17  "
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_df[user_df['cluster'] == 17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "d5157156-ac6d-4128-8588-5606a9cc8ff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_id    city  location_x  location_y  age  gender  \\\n",
      "0        1  Béchar      31.600      -2.250   48    Male   \n",
      "1        3  Béchar      31.610      -2.226   58  Female   \n",
      "2       10  Béchar      31.635      -2.217   44  Female   \n",
      "3       11  Béchar      31.615      -2.270   51    Male   \n",
      "4        2  Biskra      34.850       5.750   35  Female   \n",
      "\n",
      "                         service_categories_interest  cluster  \n",
      "0             [Commercial Cleaning, Quranic Studies]        2  \n",
      "1  [Post-Construction Cleaning, Quranic Studies, ...        0  \n",
      "2  [Quranic Studies, Tire Services, Event Caterin...        3  \n",
      "3  [Furniture Moving, Elderly Companionship Servi...        1  \n",
      "4                         [Masonry, Makeup Services]        6  \n"
     ]
    }
   ],
   "source": [
    "# Display the first few rows of the user dataset with cluster labels\n",
    "print(user_df[['user_id', 'city', 'location_x', 'location_y', 'age', 'gender', 'service_categories_interest', 'cluster']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "4ffd08fb-899d-40a1-8629-b49fd763513d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset saved as 'clustered_user_data.xlsx'\n"
     ]
    }
   ],
   "source": [
    "user_df.to_excel('clustered_user_data.xlsx', index=False)\n",
    "print(\"Dataset saved as 'clustered_user_data.xlsx'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06787b3-5d9c-401f-a0b9-ee1a7d976d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "service_df.to_excel('service_data.xlsx', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
